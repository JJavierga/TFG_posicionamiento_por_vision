#include <ros/ros.h>
#include <stdio.h>
#include <iostream>
#include <fstream>
#include <string>
#include <image_transport/image_transport.h>
#include "geometry_msgs/PoseStamped.h"
#include <opencv2/highgui.hpp>
#include <cv_bridge/cv_bridge.h>
#include <opencv2/imgcodecs.hpp>
#include "opencv2/core.hpp"
#include "opencv2/imgproc.hpp"
#include "opencv2/features2d.hpp"
#include "opencv2/highgui.hpp"
#include "opencv2/calib3d.hpp"
#include "opencv2/xfeatures2d.hpp"
#include "Euler.hpp"
#include <opencv2/aruco.hpp>

std::ofstream file;
cv::Point3d pos;

EulerAngles transf={0,CV_PI,CV_PI/2};
const Mat Rot=ComposeRotation(transf);//Matriz de cambio de base UAV-camara

const Mat CameraMatrix = (Mat_<double>(3,3) << 374.67,0,320.5,0,374.67,180.5,0,0,1);//Matriz intrínseca de la cámara

void imageCallback(const sensor_msgs::ImageConstPtr& msg)
{

  	try
  	{
	   // Lectura de imágenes
  	 Mat img_scene = cv_bridge::toCvShare(msg, "mono8")->image;
 	 if(!img_scene.data )
 	 { std::cout<< " --(!) Error reading images " << std::endl;}

	  // Toma como diccionario el de 6x6
 	cv::aruco::Dictionary dictionary =   cv::aruco::getPredefinedDictionary(cv::aruco::DICT_6X6_250);	

  	 std::vector<int> ids;
         std::vector<std::vector<cv::Point2f> > corners;

	   // Busca marcadores
         cv::aruco::detectMarkers(img_scene, dictionary, corners, ids);

	   // Si detecta al menos un marcador
	if(ids.size()>0)
	 {
		// Estima posición del marcador con respecto a la cámara
             std::vector<cv::Vec3d> rvecs, tvecs;
             cv::aruco::estimatePoseSingleMarkers(corners, 0.45215, CameraMatrix, cv::Mat(), rvecs, tvecs);
	     Mat rot_mat;
	     
	     EulerAngles angles;

	     EulerAngles mean_angles={0,0,0};

	     int i=0,j=0;
	     for(i=0;i<ids.size();i++)
	     {
		if(ids[i]==23 || ids[i]==1 || ids[i]==2 || ids[i]==5 || ids[i]==6)//Para limitar los marcadores, comentar algunos ids
		{Rodrigues(rvecs[i],rot_mat);

	    	angles=fast_Euler_angles(rot_mat.t()*Rot);

		mean_angles.roll+=angles.roll;
		mean_angles.pitch+=angles.pitch;
		mean_angles.yaw+=angles.yaw; j++;}
	     }
		//Media de ángulos medidos
	     mean_angles.roll=mean_angles.roll/(double)j;
	     mean_angles.pitch=mean_angles.pitch/(double)j;
	     mean_angles.yaw=mean_angles.yaw/(double)j;

	     Mat mean_rot_mat=ComposeRotation(mean_angles)*Rot.t(); 
		

	     Mat t_aux, tras_aux;
	     cv::Point3d mean_tras(0,0,0);
	     for(i=0;i<ids.size();i++)
	     {
		if( ids[i]==23 || ids[i]==1 || ids[i]==2 || ids[i]==5 || ids[i]==6)//Para limitar los marcadores
		{t_aux=(Mat_<double>(3,1) << tvecs[i][0], tvecs[i][1], tvecs[i][2]);
		tras_aux= -1*mean_rot_mat.t()*t_aux;
		mean_tras.x+=tras_aux.at<double>(0);
		mean_tras.y+=tras_aux.at<double>(1);
		mean_tras.z+=tras_aux.at<double>(2);
		
		// Para 9 marcadores, los offsets de los que se encuentran a la derecha del centro se compensan con aquellos de la izquierda e igual para arriba y abajo.
		// Para 3 marcadores, habría que añadir un offset de 1.5m en el total en X e Y.
	     }
	    
		//Media de las traslaciones
	    mean_tras.x=(mean_tras.x)/(double)j;
 	    mean_tras.y=(mean_tras.y)/(double)j;
 	    mean_tras.z=mean_tras.z/(double)j;

		//Guardamos en archivo
	    file.open("/home/javier/pruebas/MasPruebas/Data/Marker_pose.txt", std::ios_base::app);
      	     file << msg->header.stamp << ", " <<  mean_angles.roll << "," << mean_angles.pitch << "," << mean_angles.yaw << "," << mean_tras.x << "," <<  mean_tras.y << "," << mean_tras.z << std::endl;
	     file.close();

	   }

	 cv::waitKey(30);

  	}
 	catch (cv_bridge::Exception& e)
  	{
 	   ROS_ERROR("Could not convert from '%s' to 'bgr8'.", msg->encoding.c_str());
 	}
  
}

int main(int argc, char **argv)
{
   //Configuración de nodos y topics de ROS
  ros::init(argc, argv, "Marker_image2pose");
  ros::NodeHandle nh;
  image_transport::ImageTransport it(nh);
  image_transport::Subscriber sub_img = it.subscribe("/erlecopter/bottom/image_raw", 1, imageCallback);
  ros::spin();
}
